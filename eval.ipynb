{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, linear_model, tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "DATASET_PATH = \"C:\\\\Users\\\\Marek\\\\PycharmProjects\\\\DP\\\\venv\\\\KDDTrain+.txt\"\n",
    "DATASET_PATH_TEST = \"C:\\\\Users\\\\Marek\\\\PycharmProjects\\\\DP\\\\venv\\\\KDDTest+.txt\"\n",
    "\n",
    "# Load dataset\n",
    "flow_data_headers = [\"duration\", \"protocol\", \"service\", \"flag\", \"src-bytes\", \"dst-bytes\", \"land\", \"wrong-fragment\", \"urgent\", \"hot\", \"num-failed-logins\", \"logged-in\", \"num-compromised\", \"root-shell\", \"su-attempted\", \"num-root\", \"num-file-creations\", \"num-shells\", \"num-access-files\", \"num-outbound-cmds\", \"is-host-login\", \"is-guest-login\", \"count\", \"srv-count\", \"serror-rate\", \"srv-serror-rate\", \"rerror-rate\", \"srv-rerror-rate\", \"same-srv-rate\", \"diff-srv-rate\", \"srv-diff-host-rate\", \"dst-host-count\", \"dst-host-srv-count\", \"dst-host-same-srv-rate\", \"dst-host-diff-srv-rate\", \"dst-host-same-src-port-rate\", \"dst-host-srv-diff-host-rate\", \"dst-host-serror-rate\", \"dst-host-srv-serror-rate\", \"dst-host-rerror-rate\", \"dst-host-srv-rerror-rate\", \"label\", \"difficulty\"]\n",
    "flow_data = pd.read_csv(DATASET_PATH, names=flow_data_headers)\n",
    "flow_data_test = pd.read_csv(DATASET_PATH_TEST, names=flow_data_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satan', 'portsweep', 'other', 'ipsweep', 'nmap'}\n"
     ]
    }
   ],
   "source": [
    "# Keep only Probe attacks labeled - label other entries as \"other\"\n",
    "flow_data = flow_data.replace(['rootkit', 'ftp_write', 'buffer_overflow', 'loadmodule', 'spy', 'land', 'warezclient', 'phf', 'normal', 'pod', 'back', 'neptune', 'perl', 'imap', 'warezmaster', 'multihop', 'teardrop', 'smurf', 'guess_passwd'], 'other')\n",
    "print (set(flow_data[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations :: 125973\n",
      "Number of columns :: 43\n",
      "Headers :: ['duration' 'protocol' 'service' 'flag' 'src-bytes' 'dst-bytes' 'land'\n",
      " 'wrong-fragment' 'urgent' 'hot' 'num-failed-logins' 'logged-in'\n",
      " 'num-compromised' 'root-shell' 'su-attempted' 'num-root'\n",
      " 'num-file-creations' 'num-shells' 'num-access-files' 'num-outbound-cmds'\n",
      " 'is-host-login' 'is-guest-login' 'count' 'srv-count' 'serror-rate'\n",
      " 'srv-serror-rate' 'rerror-rate' 'srv-rerror-rate' 'same-srv-rate'\n",
      " 'diff-srv-rate' 'srv-diff-host-rate' 'dst-host-count'\n",
      " 'dst-host-srv-count' 'dst-host-same-srv-rate' 'dst-host-diff-srv-rate'\n",
      " 'dst-host-same-src-port-rate' 'dst-host-srv-diff-host-rate'\n",
      " 'dst-host-serror-rate' 'dst-host-srv-serror-rate' 'dst-host-rerror-rate'\n",
      " 'dst-host-srv-rerror-rate' 'label' 'difficulty']\n"
     ]
    }
   ],
   "source": [
    "# Train data information\n",
    "print (\"Number of observations ::\", len(flow_data.index))\n",
    "print (\"Number of columns ::\", len(flow_data.columns))\n",
    "print (\"Headers ::\", flow_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train RFC: 16.140625s\n",
      "Time to train LR: 12.21875s\n",
      "Time to train DT: 4.234375s\n",
      "[[  700     1     0     0     7]\n",
      " [    0   719     0     2     0]\n",
      " [    0     0   552     0     0]\n",
      " [    0     3     0   298     1]\n",
      " [    0     0     1     0 22911]]\n",
      "Random forest Test Accuracy ::  0.9994046437785274\n",
      "Random forest F1 Score ::  [0.99431818 0.99584488 0.99909502 0.99003322 0.99980363]\n",
      "[[  599     1     3     1   104]\n",
      " [    0   700     0     7    14]\n",
      " [    9     1   524     0    18]\n",
      " [    4     9     0   278    11]\n",
      " [   25    27     1     4 22855]]\n",
      "Logistic regression Test Accuracy ::  0.9905139908712046\n",
      "Logistic regression F1 Score ::  [0.89070632 0.95956134 0.97037037 0.93918919 0.99555691]\n",
      "[[  701     0     4     0     3]\n",
      " [    0   720     0     1     0]\n",
      " [    1     0   551     0     0]\n",
      " [    0     3     0   299     0]\n",
      " [    3     0     0     0 22909]]\n",
      "Decision tree Test Accuracy ::  0.9994046437785274\n",
      "Decision tree F1 Score ::  [0.99221515 0.99722992 0.99548329 0.99335548 0.99986906]\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier, logistic regression, decision tree\n",
    "# Training and validation using only the training dataset\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(flow_data[flow_data_headers[:-2]], \n",
    "                                                    flow_data[flow_data_headers[-2]], \n",
    "                                                    train_size=0.8, \n",
    "                                                    test_size=0.2)\n",
    "\n",
    "# One-hot encoding of categorical data, use StandardScaler for other data\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), \n",
    "                                        [\"protocol\", \"service\", \"flag\"])], \n",
    "                                      remainder=StandardScaler())\n",
    "    \n",
    "# Train Random forest classifier\n",
    "rfc = make_pipeline(columnTransformer, RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "start1 = time.process_time()\n",
    "rfc.fit(train_x, train_y)\n",
    "\n",
    "print('Time to train RFC: ' + str(time.process_time() - start1) + 's')\n",
    "\n",
    "# Train logistic regression\n",
    "mul_lr = make_pipeline(columnTransformer, linear_model.LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=20))\n",
    "\n",
    "start2 = time.process_time()\n",
    "mul_lr.fit(train_x, train_y)\n",
    "print('Time to train LR: ' + str(time.process_time() - start2) + 's')\n",
    "\n",
    "# Train Decision tree classifier\n",
    "dt = make_pipeline(columnTransformer, tree.DecisionTreeClassifier())\n",
    "\n",
    "start3 = time.process_time()\n",
    "dt.fit(train_x, train_y)\n",
    "print('Time to train DT: ' + str(time.process_time() - start3) + 's')\n",
    "\n",
    "trafficLabels = ['satan', 'ipsweep', 'portsweep', 'nmap', 'other']\n",
    "\n",
    "# Print out the results\n",
    "print(metrics.confusion_matrix(test_y, rfc.predict(test_x), labels=trafficLabels))\n",
    "print(\"Random forest Test Accuracy :: \", metrics.accuracy_score(test_y, rfc.predict(test_x)))\n",
    "print(\"Random forest F1 Score :: \", metrics.f1_score(test_y, rfc.predict(test_x), average=None, labels=trafficLabels))\n",
    "\n",
    "print(metrics.confusion_matrix(test_y, mul_lr.predict(test_x), labels=trafficLabels))\n",
    "print(\"Logistic regression Test Accuracy :: \", metrics.accuracy_score(test_y, mul_lr.predict(test_x)))\n",
    "print(\"Logistic regression F1 Score :: \", metrics.f1_score(test_y, mul_lr.predict(test_x), average=None, labels=trafficLabels))\n",
    "\n",
    "print(metrics.confusion_matrix(test_y, dt.predict(test_x), labels=trafficLabels))\n",
    "print(\"Decision tree Test Accuracy :: \", metrics.accuracy_score(test_y, dt.predict(test_x)))\n",
    "print(\"Decision tree F1 Score :: \", metrics.f1_score(test_y, dt.predict(test_x), average=None, labels=trafficLabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train RFC: 15.21875s\n",
      "Time to train LR: 1.203125s\n",
      "Time to train DT: 0.953125s\n",
      "[[  757     0     0     0     8]\n",
      " [    1   734     0     5     6]\n",
      " [    0     0   595     0     4]\n",
      " [    0     8     0   304     4]\n",
      " [    2     1     0     0 22766]]\n",
      "Random forest Test Accuracy ::  0.9984520738241714\n",
      "Random forest F1 Score ::  [0.99278689 0.98589657 0.99664992 0.9728     0.99945124]\n",
      "[[  605     0     0     0   160]\n",
      " [    0   718     0    11    17]\n",
      " [    2     0   582     0    15]\n",
      " [    0     7     1   271    37]\n",
      " [   28    31     4     7 22699]]\n",
      "Logistic regression Test Accuracy ::  0.9872990672752531\n",
      "Logistic regression F1 Score ::  [0.86428571 0.95605859 0.98145025 0.89586777 0.9934569 ]\n",
      "[[  755     0     0     0    10]\n",
      " [    1   735     0     5     5]\n",
      " [    2     0   595     0     2]\n",
      " [    0    10     0   302     4]\n",
      " [    6     1     2     1 22759]]\n",
      "Decision tree Test Accuracy ::  0.9980551696765231\n",
      "Decision tree F1 Score ::  [0.98757358 0.98525469 0.99498328 0.96794872 0.99931941]\n"
     ]
    }
   ],
   "source": [
    "# We can see that all the models have achieved very high evaluation metrics. \n",
    "# We will use the testing dataset later to see how much overfitting comes into play.\n",
    "\n",
    "# With feature selection, training and validation using only the training dataset\n",
    "\n",
    "selected_features = ['dst-host-same-src-port-rate','dst-host-count','dst-host-rerror-rate', 'rerror-rate', 'dst-host-srv-diff-host-rate', 'service', 'dst-host-srv-count', 'srv-diff-host-rate', 'dst-host-same-srv-rate', 'count', 'flag', 'dst-host-diff-srv-rate', 'protocol', 'label']\n",
    "flow_data_selected = flow_data[selected_features]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(flow_data_selected[selected_features[:-1]],\n",
    "                                                    flow_data_selected[selected_features[-1]], \n",
    "                                                    train_size=0.8, \n",
    "                                                    test_size=0.2)\n",
    "\n",
    "# One-hot encoding of categorical data, use StandardScaler for other data\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), \n",
    "                                        [\"protocol\", \"service\", \"flag\"])], \n",
    "                                      remainder=StandardScaler())\n",
    "\n",
    "# Train Random forest classifier\n",
    "rfc = make_pipeline(columnTransformer, RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "start1 = time.process_time()\n",
    "rfc.fit(train_x, train_y)\n",
    "print('Time to train RFC: ' + str(time.process_time() - start1) + 's')\n",
    "\n",
    "# Train logistic regression\n",
    "mul_lr = make_pipeline(columnTransformer, linear_model.LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=20))\n",
    "\n",
    "start2 = time.process_time()\n",
    "mul_lr.fit(train_x, train_y)\n",
    "print('Time to train LR: ' + str(time.process_time() - start2) + 's')\n",
    "\n",
    "# Train Decision Tree classifier\n",
    "dt = make_pipeline(columnTransformer, tree.DecisionTreeClassifier())\n",
    "\n",
    "start3 = time.process_time()\n",
    "dt.fit(train_x, train_y)\n",
    "print('Time to train DT: ' + str(time.process_time() - start3) + 's')\n",
    "\n",
    "trafficLabels = ['satan', 'ipsweep', 'portsweep', 'nmap', 'other']\n",
    "\n",
    "print(metrics.confusion_matrix(test_y, rfc.predict(test_x), labels=trafficLabels))\n",
    "print(\"Random forest Test Accuracy :: \", metrics.accuracy_score(test_y, rfc.predict(test_x)))\n",
    "print(\"Random forest F1 Score :: \", metrics.f1_score(test_y, rfc.predict(test_x), average=None, labels=trafficLabels))\n",
    "\n",
    "print(metrics.confusion_matrix(test_y, mul_lr.predict(test_x), labels=trafficLabels))\n",
    "print(\"Logistic regression Test Accuracy :: \", metrics.accuracy_score(test_y, mul_lr.predict(test_x)))\n",
    "print(\"Logistic regression F1 Score :: \", metrics.f1_score(test_y, mul_lr.predict(test_x), average=None, labels=trafficLabels))\n",
    "\n",
    "print(metrics.confusion_matrix(test_y, dt.predict(test_x), labels=trafficLabels))\n",
    "print(\"Decision tree Test Accuracy :: \", metrics.accuracy_score(test_y, dt.predict(test_x)))\n",
    "print(\"Decision tree F1 Score :: \", metrics.f1_score(test_y, dt.predict(test_x), average=None, labels=trafficLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations :: 22544\n",
      "Number of columns :: 43\n",
      "Headers :: ['duration' 'protocol' 'service' 'flag' 'src-bytes' 'dst-bytes' 'land'\n",
      " 'wrong-fragment' 'urgent' 'hot' 'num-failed-logins' 'logged-in'\n",
      " 'num-compromised' 'root-shell' 'su-attempted' 'num-root'\n",
      " 'num-file-creations' 'num-shells' 'num-access-files' 'num-outbound-cmds'\n",
      " 'is-host-login' 'is-guest-login' 'count' 'srv-count' 'serror-rate'\n",
      " 'srv-serror-rate' 'rerror-rate' 'srv-rerror-rate' 'same-srv-rate'\n",
      " 'diff-srv-rate' 'srv-diff-host-rate' 'dst-host-count'\n",
      " 'dst-host-srv-count' 'dst-host-same-srv-rate' 'dst-host-diff-srv-rate'\n",
      " 'dst-host-same-src-port-rate' 'dst-host-srv-diff-host-rate'\n",
      " 'dst-host-serror-rate' 'dst-host-srv-serror-rate' 'dst-host-rerror-rate'\n",
      " 'dst-host-srv-rerror-rate' 'label' 'difficulty']\n"
     ]
    }
   ],
   "source": [
    "# We can see that reducing the number of features sped the learning models slightly, at the expense of losing some accuracy.\n",
    "\n",
    "# Test data information\n",
    "print (\"Number of observations ::\", len(flow_data_test.index))\n",
    "print (\"Number of columns ::\", len(flow_data_test.columns))\n",
    "print (\"Headers ::\", flow_data_test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'other', 'probe'}\n",
      "{'other', 'probe'}\n"
     ]
    }
   ],
   "source": [
    "# In the testing dataset, some attack types previously unseen appear.\n",
    "\n",
    "# With feature selection, training on training dataset and validation using only the test dataset\n",
    "\n",
    "selected_features = ['dst-host-same-src-port-rate','dst-host-count','dst-host-rerror-rate', 'rerror-rate', 'dst-host-srv-diff-host-rate', 'service', 'dst-host-srv-count', 'srv-diff-host-rate', 'dst-host-same-srv-rate', 'count', 'flag', 'dst-host-diff-srv-rate', 'protocol', 'label']\n",
    "flow_data = flow_data[selected_features]\n",
    "flow_data_test = flow_data_test[selected_features]\n",
    "\n",
    "# Classify non-Probe traffic as \"other\"\n",
    "flow_data_test = flow_data_test.replace(['rootkit', 'ftp_write', 'buffer_overflow', 'loadmodule', 'spy', 'land', 'warezclient', 'phf', 'normal', 'pod', 'back', 'neptune', 'perl', 'imap', 'warezmaster', 'multihop', 'teardrop', 'smurf', 'guess_passwd'], 'other')\n",
    "\n",
    "# Create one unifying label \"probe\"\n",
    "flow_data = flow_data.replace(['satan', 'portsweep', 'ipsweep', 'nmap'], 'probe')\n",
    "\n",
    "# Create one unifying label \"probe\"\n",
    "flow_data_test = flow_data_test.replace(\n",
    "    ['satan', 'portsweep', 'ipsweep', 'nmap', 'saint', 'mscan'], 'probe')\n",
    "\n",
    "# Classify test-exclusive traffic as \"other\"\n",
    "flow_data_test = flow_data_test.replace(\n",
    "    ['sendmail', 'snmpgetattack', 'named', 'ps', 'apache2', 'snmpguess', 'processtable', 'worm', 'xsnoop', 'udpstorm', 'sqlattack', 'httptunnel', 'xlock', 'mailbomb', 'xterm'], 'other')\n",
    "\n",
    "print(set(flow_data[\"label\"]))\n",
    "print(set(flow_data_test[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train RFC: 20.015625s\n",
      "Time to train LR: 0.75s\n",
      "Time to train DT: 1.25s\n",
      "[[ 1306  1115]\n",
      " [  230 19893]]\n",
      "Random forest Test Accuracy ::  0.9403388928317956\n",
      "Random forest F1 Score ::  [0.66009603 0.9672996 ]\n",
      "[[ 1341  1080]\n",
      " [  614 19509]]\n",
      "Logistic regression Test Accuracy ::  0.9248580553584103\n",
      "Logistic regression F1 Score ::  [0.61288848 0.95839065]\n",
      "[[ 1339  1082]\n",
      " [  543 19580]]\n",
      "Decision tree Test Accuracy ::  0.9279187366926899\n",
      "Decision tree F1 Score ::  [0.6223565  0.96015692]\n"
     ]
    }
   ],
   "source": [
    "train_x = flow_data[selected_features[:-1]]\n",
    "train_y = flow_data[selected_features[-1]]\n",
    "test_x = flow_data_test[selected_features[:-1]]\n",
    "test_y = flow_data_test[selected_features[-1]]\n",
    "\n",
    "# Train Random Forest classifier\n",
    "rfc = make_pipeline(columnTransformer, RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "start1 = time.process_time()\n",
    "rfc.fit(train_x, train_y)\n",
    "print('Time to train RFC: ' + str(time.process_time() - start1) + 's')\n",
    "\n",
    "# Train logistic regression\n",
    "mul_lr = make_pipeline(columnTransformer, linear_model.LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=20))\n",
    "\n",
    "start2 = time.process_time()\n",
    "mul_lr.fit(train_x, train_y)\n",
    "print('Time to train LR: ' + str(time.process_time() - start2) + 's')\n",
    "\n",
    "# Train Decision Tree classifier\n",
    "dt = make_pipeline(columnTransformer, tree.DecisionTreeClassifier())\n",
    "\n",
    "start3 = time.process_time()\n",
    "dt.fit(train_x, train_y)\n",
    "print('Time to train DT: ' + str(time.process_time() - start3) + 's')\n",
    "\n",
    "trafficLabels = ['probe', 'other']\n",
    "\n",
    "print(metrics.confusion_matrix(test_y, rfc.predict(test_x), labels=trafficLabels))\n",
    "print(\"Random forest Test Accuracy :: \", metrics.accuracy_score(test_y, rfc.predict(test_x)))\n",
    "print(\"Random forest F1 Score :: \",\n",
    "      metrics.f1_score(test_y, rfc.predict(test_x), average=None, labels=trafficLabels))\n",
    "\n",
    "print(metrics.confusion_matrix(test_y, mul_lr.predict(test_x), labels=trafficLabels))\n",
    "print(\"Logistic regression Test Accuracy :: \", metrics.accuracy_score(test_y, mul_lr.predict(test_x)))\n",
    "print(\"Logistic regression F1 Score :: \", metrics.f1_score(test_y, mul_lr.predict(test_x), average=None, labels=trafficLabels))\n",
    "\n",
    "print(metrics.confusion_matrix(test_y, dt.predict(test_x), labels=trafficLabels))\n",
    "print(\"Decision tree Test Accuracy :: \", metrics.accuracy_score(test_y, dt.predict(test_x)))\n",
    "print(\"Decision tree F1 Score :: \", metrics.f1_score(test_y, dt.predict(test_x), average=None, labels=trafficLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'other', 'probe'}\n",
      "{'other', 'probe'}\n"
     ]
    }
   ],
   "source": [
    "# We can see that the proportion of undetected attacks rose significantly when using the testing dataset. \n",
    "# We will now remove previously unseen types of attacks, in order to test that these are the records that cause a lower accuracy.\n",
    "\n",
    "# With feature selection, training on training dataset and validation using only the test dataset\n",
    "\n",
    "flow_data_test = pd.read_csv(DATASET_PATH_TEST, names=flow_data_headers)\n",
    "selected_features = ['dst-host-same-src-port-rate','dst-host-count','dst-host-rerror-rate', 'rerror-rate', 'dst-host-srv-diff-host-rate', 'service', 'dst-host-srv-count', 'srv-diff-host-rate', 'dst-host-same-srv-rate', 'count', 'flag', 'dst-host-diff-srv-rate', 'protocol', 'label']\n",
    "flow_data = flow_data[selected_features]\n",
    "flow_data_test = flow_data_test[selected_features]\n",
    "\n",
    "# Classify non-Probe traffic as \"other\"\n",
    "flow_data_test = flow_data_test.replace(['rootkit', 'ftp_write', 'buffer_overflow', 'loadmodule', 'spy', 'land', 'warezclient', 'phf', 'normal', 'pod', 'back', 'neptune', 'perl', 'imap', 'warezmaster', 'multihop', 'teardrop', 'smurf', 'guess_passwd'], 'other')\n",
    "\n",
    "# Remove previously unseen attacks from the testing dataset\n",
    "flow_data_test.drop(flow_data_test[flow_data_test.label == 'saint'].index, inplace=True)\n",
    "flow_data_test.drop(flow_data_test[flow_data_test.label == 'mscan'].index, inplace=True)\n",
    "\n",
    "# Create one unifying label \"probe\"\n",
    "flow_data = flow_data.replace(['satan', 'portsweep', 'ipsweep', 'nmap'], 'probe')\n",
    "\n",
    "# Create one unifying label \"probe\"\n",
    "flow_data_test = flow_data_test.replace(\n",
    "    ['satan', 'portsweep', 'ipsweep', 'nmap'], 'probe')\n",
    "\n",
    "# Classify test-exclusive traffic as \"other\"\n",
    "flow_data_test = flow_data_test.replace(\n",
    "    ['sendmail', 'snmpgetattack', 'named', 'ps', 'apache2', 'snmpguess', 'processtable', 'worm', 'xsnoop', 'udpstorm', 'sqlattack', 'httptunnel', 'xlock', 'mailbomb', 'xterm'], 'other')\n",
    "\n",
    "print(set(flow_data[\"label\"]))\n",
    "print(set(flow_data_test[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train RFC: 17.328125s\n",
      "Time to train LR: 0.59375s\n",
      "Time to train DT: 1.109375s\n",
      "[[  982   124]\n",
      " [  223 19900]]\n",
      "Random forest Test Accuracy ::  0.9836544349710302\n",
      "Random forest F1 Score ::  [0.84984855 0.99135676]\n",
      "[[ 1011    95]\n",
      " [  614 19509]]\n",
      "Logistic regression Test Accuracy ::  0.9666022893212115\n",
      "Logistic regression F1 Score ::  [0.74038814 0.9821532 ]\n",
      "[[  987   119]\n",
      " [  616 19507]]\n",
      "Decision tree Test Accuracy ::  0.9653775495784069\n",
      "Decision tree F1 Score ::  [0.72868217 0.98150897]\n"
     ]
    }
   ],
   "source": [
    "train_x = flow_data[selected_features[:-1]]\n",
    "train_y = flow_data[selected_features[-1]]\n",
    "test_x = flow_data_test[selected_features[:-1]]\n",
    "test_y = flow_data_test[selected_features[-1]]\n",
    "\n",
    "# Train Random Forest classifier\n",
    "rfc = make_pipeline(columnTransformer, RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "start1 = time.process_time()\n",
    "rfc.fit(train_x, train_y)\n",
    "print('Time to train RFC: ' + str(time.process_time() - start1) + 's')\n",
    "\n",
    "# Train logistic regression\n",
    "mul_lr = make_pipeline(columnTransformer, linear_model.LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=20))\n",
    "\n",
    "start2 = time.process_time()\n",
    "mul_lr.fit(train_x, train_y)\n",
    "print('Time to train LR: ' + str(time.process_time() - start2) + 's')\n",
    "\n",
    "# Train Decision Tree classifier\n",
    "dt = make_pipeline(columnTransformer, tree.DecisionTreeClassifier())\n",
    "\n",
    "start3 = time.process_time()\n",
    "dt.fit(train_x, train_y)\n",
    "print('Time to train DT: ' + str(time.process_time() - start3) + 's')\n",
    "\n",
    "trafficLabels = ['probe', 'other']\n",
    "\n",
    "print(metrics.confusion_matrix(test_y, rfc.predict(test_x), labels=trafficLabels))\n",
    "print(\"Random forest Test Accuracy :: \", metrics.accuracy_score(test_y, rfc.predict(test_x)))\n",
    "print(\"Random forest F1 Score :: \",\n",
    "      metrics.f1_score(test_y, rfc.predict(test_x), average=None, labels=trafficLabels))\n",
    "\n",
    "print(metrics.confusion_matrix(test_y, mul_lr.predict(test_x), labels=trafficLabels))\n",
    "print(\"Logistic regression Test Accuracy :: \", metrics.accuracy_score(test_y, mul_lr.predict(test_x)))\n",
    "print(\"Logistic regression F1 Score :: \", metrics.f1_score(test_y, mul_lr.predict(test_x), average=None, labels=trafficLabels))\n",
    "\n",
    "print(metrics.confusion_matrix(test_y, dt.predict(test_x), labels=trafficLabels))\n",
    "print(\"Decision tree Test Accuracy :: \", metrics.accuracy_score(test_y, dt.predict(test_x)))\n",
    "print(\"Decision tree F1 Score :: \", metrics.f1_score(test_y, dt.predict(test_x), average=None, labels=trafficLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  protocol service  dst-host-count  dst-host-srv-count  \\\n",
      "0      tcp    http               9                   9   \n",
      "\n",
      "   dst-host-same-srv-rate  dst-host-same-src-port-rate  label  \n",
      "0                     1.0                         0.11  other  \n"
     ]
    }
   ],
   "source": [
    "# We can see that only including attacks previously seen attacks vastly decreased the proportion of false negatives (top left).\n",
    "# We will investigate further on how to improve accuracy with unseen attacks.\n",
    "\n",
    "# Finally, we trained our models on the training dataset and classified the new record output by out SDN testbed.\n",
    "CUSTOM_DATASET_PATH = \"C:\\\\Users\\\\Marek\\\\PycharmProjects\\\\DP\\\\venv\\\\CustomTest.txt\"\n",
    "\n",
    "flow_data = pd.read_csv(DATASET_PATH, names=flow_data_headers)\n",
    "selected_features = ['protocol','service','dst-host-count','dst-host-srv-count','dst-host-same-srv-rate','dst-host-same-src-port-rate','label']\n",
    "flow_data = flow_data[selected_features]\n",
    "\n",
    "# Load the record retrieved from the SDN testbed.\n",
    "flow_data_test = pd.read_csv(CUSTOM_DATASET_PATH, names=selected_features)\n",
    "print(flow_data_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train RFC: 24.140625s\n",
      "Time to train LR: 1.265625s\n",
      "Time to train DT: 0.78125s\n",
      "['Prediction by Random Forest: other']\n",
      "['Prediction by Logistic regression: other']\n",
      "['Prediction by Decision tree: other']\n"
     ]
    }
   ],
   "source": [
    "# Keep only Probe attacks labeled - label other entries as \"other\"\n",
    "flow_data = flow_data.replace(['rootkit', 'ftp_write', 'buffer_overflow', 'loadmodule', 'spy', 'land', 'warezclient', 'phf', 'normal', 'pod', 'back', 'neptune', 'perl', 'imap', 'warezmaster', 'multihop', 'teardrop', 'smurf', 'guess_passwd'], 'other')\n",
    "\n",
    "train_x = flow_data[selected_features[:-1]]\n",
    "train_y = flow_data[selected_features[-1]]\n",
    "test_x = flow_data_test[selected_features[:-1]]\n",
    "test_y = flow_data_test[selected_features[-1]]\n",
    "\n",
    "# One-hot encoding of categorical data, use StandardScaler for other data\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), \n",
    "                                        [\"protocol\", \"service\"])], \n",
    "                                      remainder=StandardScaler())\n",
    "\n",
    "# Train Random forest classifier\n",
    "rfc = make_pipeline(columnTransformer, RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "start1 = time.process_time()\n",
    "rfc.fit(train_x, train_y)\n",
    "print('Time to train RFC: ' + str(time.process_time() - start1) + 's')\n",
    "\n",
    "# Train logistic regression\n",
    "mul_lr = make_pipeline(columnTransformer, linear_model.LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=20))\n",
    "\n",
    "start2 = time.process_time()\n",
    "mul_lr.fit(train_x, train_y)\n",
    "print('Time to train LR: ' + str(time.process_time() - start2) + 's')\n",
    "\n",
    "# Train Decision Tree classifier\n",
    "dt = make_pipeline(columnTransformer, tree.DecisionTreeClassifier())\n",
    "\n",
    "start3 = time.process_time()\n",
    "dt.fit(train_x, train_y)\n",
    "print('Time to train DT: ' + str(time.process_time() - start3) + 's')\n",
    "\n",
    "trafficLabels = ['satan', 'ipsweep', 'portsweep', 'nmap', 'other']\n",
    "\n",
    "print('Prediction by Random Forest: ' + rfc.predict(test_x))\n",
    "\n",
    "print('Prediction by Logistic regression: ' + mul_lr.predict(test_x))\n",
    "\n",
    "print('Prediction by Decision tree: ' + dt.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All classifiers correctly classified the record as non-malicious."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
