{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from collections import Counter\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, linear_model, tree, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "DATASET_PATH = \"C:\\\\Users\\\\Marek\\\\PycharmProjects\\\\DP\\\\venv\\\\Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\"\n",
    "\n",
    "# Load dataset\n",
    "flow_data_headers = [\"Destination Port\", \"Flow Duration\", \"Total Fwd Packets\", \"Total Backward Packets\",\"Total Length of Fwd Packets\", \"Total Length of Bwd Packets\", \"Fwd Packet Length Max\", \"Fwd Packet Length Min\", \"Fwd Packet Length Mean\", \"Fwd Packet Length Std\",\"Bwd Packet Length Max\", \"Bwd Packet Length Min\", \"Bwd Packet Length Mean\", \"Bwd Packet Length Std\",\"Flow Bytes/s\", \"Flow Packets/s\", \"Flow IAT Mean\", \"Flow IAT Std\", \"Flow IAT Max\", \"Flow IAT Min\",\"Fwd IAT Total\", \"Fwd IAT Mean\", \"Fwd IAT Std\", \"Fwd IAT Max\", \"Fwd IAT Min\",\"Bwd IAT Total\", \"Bwd IAT Mean\", \"Bwd IAT Std\", \"Bwd IAT Max\", \"Bwd IAT Min\",\"Fwd PSH Flags\", \"Bwd PSH Flags\", \"Fwd URG Flags\", \"Bwd URG Flags\", \"Fwd Header Length\", \"Bwd Header Length\",\"Fwd Packets/s\", \"Bwd Packets/s\", \"Min Packet Length\", \"Max Packet Length\", \"Packet Length Mean\", \"Packet Length Std\", \"Packet Length Variance\",\"FIN Flag Count\", \"SYN Flag Count\", \"RST Flag Count\", \"PSH Flag Count\", \"ACK Flag Count\", \"URG Flag Count\", \"CWE Flag Count\", \"ECE Flag Count\", \"Down/Up Ratio\", \"Average Packet Size\", \"Avg Fwd Segment Size\", \"Avg Bwd Segment Size\", \"Fwd Header Lengthtwo\",\"Fwd Avg Bytes/Bulk\", \"Fwd Avg Packets/Bulk\", \"Fwd Avg Bulk Rate\", \"Bwd Avg Bytes/Bulk\", \"Bwd Avg Packets/Bulk\",\"Bwd Avg Bulk Rate\",\"Subflow Fwd Packets\", \"Subflow Fwd Bytes\", \"Subflow Bwd Packets\", \"Subflow Bwd Bytes\",\"Init_Win_bytes_forward\", \"Init_Win_bytes_backward\", \"act_data_pkt_fwd\", \"min_seg_size_forward\",\"Active Mean\", \"Active Std\", \"Active Max\", \"Active Min\",\"Idle Mean\", \"Idle Std\", \"Idle Max\", \"Idle Min\", \"Label\"]\n",
    "flow_data = pd.read_csv(DATASET_PATH, names=flow_data_headers, skiprows=1).replace('Infinity',np.inf)\n",
    "# Purge records with infinity or NaN values\n",
    "flow_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "flow_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PortScan', 'BENIGN'}\n"
     ]
    }
   ],
   "source": [
    "# Check to see labels contained in the dataset\n",
    "print(set(flow_data[\"Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations :: 286096\n",
      "Number of columns :: 79\n",
      "Headers :: ['Destination Port' 'Flow Duration' 'Total Fwd Packets'\n",
      " 'Total Backward Packets' 'Total Length of Fwd Packets'\n",
      " 'Total Length of Bwd Packets' 'Fwd Packet Length Max'\n",
      " 'Fwd Packet Length Min' 'Fwd Packet Length Mean' 'Fwd Packet Length Std'\n",
      " 'Bwd Packet Length Max' 'Bwd Packet Length Min' 'Bwd Packet Length Mean'\n",
      " 'Bwd Packet Length Std' 'Flow Bytes/s' 'Flow Packets/s' 'Flow IAT Mean'\n",
      " 'Flow IAT Std' 'Flow IAT Max' 'Flow IAT Min' 'Fwd IAT Total'\n",
      " 'Fwd IAT Mean' 'Fwd IAT Std' 'Fwd IAT Max' 'Fwd IAT Min' 'Bwd IAT Total'\n",
      " 'Bwd IAT Mean' 'Bwd IAT Std' 'Bwd IAT Max' 'Bwd IAT Min' 'Fwd PSH Flags'\n",
      " 'Bwd PSH Flags' 'Fwd URG Flags' 'Bwd URG Flags' 'Fwd Header Length'\n",
      " 'Bwd Header Length' 'Fwd Packets/s' 'Bwd Packets/s' 'Min Packet Length'\n",
      " 'Max Packet Length' 'Packet Length Mean' 'Packet Length Std'\n",
      " 'Packet Length Variance' 'FIN Flag Count' 'SYN Flag Count'\n",
      " 'RST Flag Count' 'PSH Flag Count' 'ACK Flag Count' 'URG Flag Count'\n",
      " 'CWE Flag Count' 'ECE Flag Count' 'Down/Up Ratio' 'Average Packet Size'\n",
      " 'Avg Fwd Segment Size' 'Avg Bwd Segment Size' 'Fwd Header Lengthtwo'\n",
      " 'Fwd Avg Bytes/Bulk' 'Fwd Avg Packets/Bulk' 'Fwd Avg Bulk Rate'\n",
      " 'Bwd Avg Bytes/Bulk' 'Bwd Avg Packets/Bulk' 'Bwd Avg Bulk Rate'\n",
      " 'Subflow Fwd Packets' 'Subflow Fwd Bytes' 'Subflow Bwd Packets'\n",
      " 'Subflow Bwd Bytes' 'Init_Win_bytes_forward' 'Init_Win_bytes_backward'\n",
      " 'act_data_pkt_fwd' 'min_seg_size_forward' 'Active Mean' 'Active Std'\n",
      " 'Active Max' 'Active Min' 'Idle Mean' 'Idle Std' 'Idle Max' 'Idle Min'\n",
      " 'Label']\n"
     ]
    }
   ],
   "source": [
    "# Basic data information\n",
    "print (\"Number of observations ::\", len(flow_data.index))\n",
    "print (\"Number of columns ::\", len(flow_data.columns))\n",
    "print (\"Headers ::\", flow_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PortScan    158804\n",
      "BENIGN      127292\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (flow_data['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "DATASET_PATH_TEST = \"C:\\\\Users\\\\Marek\\\\PycharmProjects\\\\DP\\\\venv\\\\dataset\\\\csv\\\\raw\\\\raw_sS.csv\"\n",
    "\n",
    "test_flow_data_headers = [\"Timestamp\", \"FlowID\", \"In Port\", \"L4 Protocol\",\"L4 Dest\", \"Total Fwd Packets\", \"Total Backward Packets\", \"Total Length of Fwd Packets\", \"Total Length of Bwd Packets\", \"Fwd IAT Mean\",\"Fwd IAT Std\", \"Fwd IAT Max\", \"Fwd IAT Min\", \"Bwd IAT Mean\",\"Bwd IAT Std\", \"Bwd IAT Max\", \"Bwd IAT Min\", \"Fwd PSH Flags\", \"Bwd PSH Flags\", \"Fwd URG Flags\", \"Bwd URG Flags\", \"Average Packet Size\", \"Avg Fwd Segment Size\", \"Avg Bwd Segment Size\"]\n",
    "test_flow_data = pd.read_csv(DATASET_PATH_TEST, names=test_flow_data_headers, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    200\n",
      "3     51\n",
      "2     51\n",
      "Name: In Port, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (test_flow_data['In Port'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(row):\n",
    "    if row['In Port'] == 1:\n",
    "        return 'PortScan'\n",
    "    else:\n",
    "        return 'BENIGN'\n",
    "\n",
    "test_flow_data['Label'] = test_flow_data.apply(lambda row: assign_label(row), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PortScan    200\n",
      "BENIGN      102\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (test_flow_data['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_flow_data.drop(test_flow_data.columns[range(5)], axis=1, inplace=True)\n",
    "test_flow_data.to_csv('processed_sS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations :: 302\n",
      "Number of columns :: 20\n",
      "Headers :: ['Total Fwd Packets' 'Total Backward Packets'\n",
      " 'Total Length of Fwd Packets' 'Total Length of Bwd Packets'\n",
      " 'Fwd IAT Mean' 'Fwd IAT Std' 'Fwd IAT Max' 'Fwd IAT Min' 'Bwd IAT Mean'\n",
      " 'Bwd IAT Std' 'Bwd IAT Max' 'Bwd IAT Min' 'Fwd PSH Flags' 'Bwd PSH Flags'\n",
      " 'Fwd URG Flags' 'Bwd URG Flags' 'Average Packet Size'\n",
      " 'Avg Fwd Segment Size' 'Avg Bwd Segment Size' 'Label']\n"
     ]
    }
   ],
   "source": [
    "# Basic data information\n",
    "print (\"Number of observations ::\", len(test_flow_data.index))\n",
    "print (\"Number of columns ::\", len(test_flow_data.columns))\n",
    "print (\"Headers ::\", test_flow_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_features = ['Total Fwd Packets', 'Total Backward Packets',\n",
    " 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', 'Label']\n",
    "\n",
    "flow_data_basic = flow_data[basic_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations :: 286096\n",
      "Number of columns :: 5\n",
      "Headers :: ['Total Fwd Packets' 'Total Backward Packets'\n",
      " 'Total Length of Fwd Packets' 'Total Length of Bwd Packets' 'Label']\n"
     ]
    }
   ],
   "source": [
    "# Basic data information\n",
    "print (\"Number of observations ::\", len(flow_data_basic.index))\n",
    "print (\"Number of columns ::\", len(flow_data_basic.columns))\n",
    "print (\"Headers ::\", flow_data_basic.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(flow_data_selected[selected_features[:-1]],\n",
    "                                                    flow_data_selected[selected_features[-1]], \n",
    "                                                    train_size=0.67, \n",
    "                                                    test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train RFC: 1.296875s\n",
      "[[41880    30]\n",
      " [    5 52497]]\n",
      "Random forest Test Accuracy ::  0.9996292844129984\n",
      "Random forest Test Sensitivity ::  0.9999047655327417\n",
      "Random forest Test Specificity ::  0.9992841803865425\n",
      "Random forest Test Precision ::  0.9994288651550631\n",
      "Random forest F1 Score ::  [0.99958231 0.99966676]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "start1 = time.process_time()\n",
    "rfc.fit(train_x, train_y)\n",
    "\n",
    "print('Time to train RFC: ' + str(time.process_time() - start1) + 's')\n",
    "\n",
    "trafficLabels = ['BENIGN', 'PortScan']\n",
    "\n",
    "# Print out the results\n",
    "print(metrics.confusion_matrix(test_y, rfc.predict(test_x), labels=trafficLabels))\n",
    "print(\"Random forest Test Accuracy :: \", metrics.accuracy_score(test_y, rfc.predict(test_x)))\n",
    "print(\"Random forest Test Sensitivity :: \", metrics.recall_score(test_y, rfc.predict(test_x), pos_label=\"PortScan\"))\n",
    "print(\"Random forest Test Specificity :: \", metrics.recall_score(test_y, rfc.predict(test_x), pos_label=\"BENIGN\"))\n",
    "print(\"Random forest Test Precision :: \", metrics.precision_score(test_y, rfc.predict(test_x), pos_label=\"PortScan\"))\n",
    "print(\"Random forest F1 Score :: \", metrics.f1_score(test_y, rfc.predict(test_x), average=None, labels=trafficLabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train GBC: 2.21875s\n",
      "[[41856    54]\n",
      " [  210 52292]]\n",
      "GBC Test Accuracy ::  0.9972037452866161\n",
      "GBC Test Sensitivity ::  0.9960001523751476\n",
      "GBC Test Specificity ::  0.9987115246957766\n",
      "GBC Test Precision ::  0.9989684025522485\n",
      "GBC F1 Score ::  [0.99685624 0.99748207]\n"
     ]
    }
   ],
   "source": [
    "# Train GradientBooster\n",
    "gbc = GradientBoostingClassifier(n_estimators=10)\n",
    "\n",
    "start4 = time.process_time()\n",
    "gbc.fit(train_x, train_y)\n",
    "\n",
    "trafficLabels = ['BENIGN', 'PortScan']\n",
    "\n",
    "print('Time to train GBC: ' + str(time.process_time() - start4) + 's')\n",
    "\n",
    "# Print out the results\n",
    "print(metrics.confusion_matrix(test_y, gbc.predict(test_x), labels=trafficLabels))\n",
    "print(\"GBC Test Accuracy :: \", metrics.accuracy_score(test_y, gbc.predict(test_x)))\n",
    "print(\"GBC Test Sensitivity :: \", metrics.recall_score(test_y, gbc.predict(test_x), pos_label=\"PortScan\"))\n",
    "print(\"GBC Test Specificity :: \", metrics.recall_score(test_y, gbc.predict(test_x), pos_label=\"BENIGN\"))\n",
    "print(\"GBC Test Precision :: \", metrics.precision_score(test_y, gbc.predict(test_x), pos_label=\"PortScan\"))\n",
    "print(\"GBC Test F1 Score :: \", metrics.f1_score(test_y, gbc.predict(test_x), average=None, labels=trafficLabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train DT: 0.40625s\n",
      "[[33304  8606]\n",
      " [   97 52405]]\n",
      "DT Test Accuracy ::  0.9078189213235606\n",
      "DT Test Sensitivity ::  0.9981524513351873\n",
      "DT Test Specificity ::  0.7946552135528514\n",
      "DT Test Precision ::  0.8589434692104703\n",
      "DT Test F1 Score ::  [0.88443919 0.92333037]\n"
     ]
    }
   ],
   "source": [
    "# Train Decision tree classifier\n",
    "dt = tree.DecisionTreeClassifier(criterion = \"gini\", splitter = 'random', max_leaf_nodes = 10, min_samples_leaf = 5, max_depth= 5)\n",
    "\n",
    "start2 = time.process_time()\n",
    "dt.fit(train_x, train_y)\n",
    "\n",
    "print('Time to train DT: ' + str(time.process_time() - start2) + 's')\n",
    "\n",
    "# Print out the results\n",
    "print(metrics.confusion_matrix(test_y, dt.predict(test_x), labels=trafficLabels))\n",
    "print(\"DT Test Accuracy :: \", metrics.accuracy_score(test_y, dt.predict(test_x)))\n",
    "print(\"DT Test Sensitivity :: \", metrics.recall_score(test_y, dt.predict(test_x), pos_label=\"PortScan\"))\n",
    "print(\"DT Test Specificity :: \", metrics.recall_score(test_y, dt.predict(test_x), pos_label=\"BENIGN\"))\n",
    "print(\"DT Test Precision :: \", metrics.precision_score(test_y, dt.predict(test_x), pos_label=\"PortScan\"))\n",
    "print(\"DT Test F1 Score :: \", metrics.f1_score(test_y, dt.predict(test_x), average=None, labels=trafficLabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Total Fwd Packets', 'Total Backward Packets',\n",
    " 'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
    " 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Mean',\n",
    " 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'PSH Flag Count',\n",
    " 'Fwd URG Flags', 'Bwd URG Flags', 'URG Flag Count', 'Average Packet Size',\n",
    " 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Label']\n",
    "\n",
    "flow_data_selected = flow_data[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations :: 286096\n",
      "Number of columns :: 22\n",
      "Headers :: ['Total Fwd Packets' 'Total Backward Packets'\n",
      " 'Total Length of Fwd Packets' 'Total Length of Bwd Packets'\n",
      " 'Fwd IAT Mean' 'Fwd IAT Std' 'Fwd IAT Max' 'Fwd IAT Min' 'Bwd IAT Mean'\n",
      " 'Bwd IAT Std' 'Bwd IAT Max' 'Bwd IAT Min' 'Fwd PSH Flags' 'Bwd PSH Flags'\n",
      " 'PSH Flag Count' 'Fwd URG Flags' 'Bwd URG Flags' 'URG Flag Count'\n",
      " 'Average Packet Size' 'Avg Fwd Segment Size' 'Avg Bwd Segment Size'\n",
      " 'Label']\n"
     ]
    }
   ],
   "source": [
    "# Basic data information\n",
    "print (\"Number of observations ::\", len(flow_data_selected.index))\n",
    "print (\"Number of columns ::\", len(flow_data_selected.columns))\n",
    "print (\"Headers ::\", flow_data_selected.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(flow_data_selected[selected_features[:-1]],\n",
    "                                                    flow_data_selected[selected_features[-1]], \n",
    "                                                    train_size=0.67, \n",
    "                                                    test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train RFC: 1.296875s\n",
      "[[41889    21]\n",
      " [    5 52497]]\n",
      "Random forest Test Accuracy ::  0.9997246112782273\n",
      "Random forest Test Sensitivity ::  0.9999047655327417\n",
      "Random forest Test Specificity ::  0.9994989262705798\n",
      "Random forest Test Precision ::  0.9996001370958528\n",
      "Random forest F1 Score ::  [0.99968975 0.99975243]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "start1 = time.process_time()\n",
    "rfc.fit(train_x, train_y)\n",
    "\n",
    "print('Time to train RFC: ' + str(time.process_time() - start1) + 's')\n",
    "\n",
    "trafficLabels = ['BENIGN', 'PortScan']\n",
    "\n",
    "# Print out the results\n",
    "print(metrics.confusion_matrix(test_y, rfc.predict(test_x), labels=trafficLabels))\n",
    "print(\"Random forest Test Accuracy :: \", metrics.accuracy_score(test_y, rfc.predict(test_x)))\n",
    "print(\"Random forest Test Sensitivity :: \", metrics.recall_score(test_y, rfc.predict(test_x), pos_label=\"PortScan\"))\n",
    "print(\"Random forest Test Specificity :: \", metrics.recall_score(test_y, rfc.predict(test_x), pos_label=\"BENIGN\"))\n",
    "print(\"Random forest Test Precision :: \", metrics.precision_score(test_y, rfc.predict(test_x), pos_label=\"PortScan\"))\n",
    "print(\"Random forest F1 Score :: \", metrics.f1_score(test_y, rfc.predict(test_x), average=None, labels=trafficLabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train GBC: 2.3125s\n",
      "[[41848    62]\n",
      " [   61 52441]]\n",
      "GBC Test Accuracy ::  0.9986971995085371\n",
      "GBC Test Sensitivity ::  0.9988381394994477\n",
      "GBC Test Specificity ::  0.9985206394655214\n",
      "GBC Test Precision ::  0.9988191150981849\n",
      "GBC Test F1 Score ::  [0.99853255 0.99882863]\n"
     ]
    }
   ],
   "source": [
    "# Train GradientBooster\n",
    "gbc = GradientBoostingClassifier(n_estimators=10)\n",
    "\n",
    "start4 = time.process_time()\n",
    "gbc.fit(train_x, train_y)\n",
    "\n",
    "trafficLabels = ['BENIGN', 'PortScan']\n",
    "\n",
    "print('Time to train GBC: ' + str(time.process_time() - start4) + 's')\n",
    "\n",
    "# Print out the results\n",
    "print(metrics.confusion_matrix(test_y, gbc.predict(test_x), labels=trafficLabels))\n",
    "print(\"GBC Test Accuracy :: \", metrics.accuracy_score(test_y, gbc.predict(test_x)))\n",
    "print(\"GBC Test Sensitivity :: \", metrics.recall_score(test_y, gbc.predict(test_x), pos_label=\"PortScan\"))\n",
    "print(\"GBC Test Specificity :: \", metrics.recall_score(test_y, gbc.predict(test_x), pos_label=\"BENIGN\"))\n",
    "print(\"GBC Test Precision :: \", metrics.precision_score(test_y, gbc.predict(test_x), pos_label=\"PortScan\"))\n",
    "print(\"GBC Test F1 Score :: \", metrics.f1_score(test_y, gbc.predict(test_x), average=None, labels=trafficLabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train DT: 0.359375s\n",
      "[[41648   262]\n",
      " [  358 52144]]\n",
      "DT Test Accuracy ::  0.9934330381731136\n",
      "DT Test Sensitivity ::  0.9931812121442992\n",
      "DT Test Specificity ::  0.9937485087091387\n",
      "DT Test Precision ::  0.9950005724535359\n",
      "DT Test F1 Score ::  [0.99261166 0.99409006]\n"
     ]
    }
   ],
   "source": [
    "# Train Decision tree classifier\n",
    "dt = tree.DecisionTreeClassifier(criterion = \"gini\", splitter = 'random', max_leaf_nodes = 10, min_samples_leaf = 5, max_depth= 5)\n",
    "\n",
    "start2 = time.process_time()\n",
    "dt.fit(train_x, train_y)\n",
    "\n",
    "print('Time to train DT: ' + str(time.process_time() - start2) + 's')\n",
    "\n",
    "# Print out the results\n",
    "print(metrics.confusion_matrix(test_y, dt.predict(test_x), labels=trafficLabels))\n",
    "print(\"DT Test Accuracy :: \", metrics.accuracy_score(test_y, dt.predict(test_x)))\n",
    "print(\"DT Test Sensitivity :: \", metrics.recall_score(test_y, dt.predict(test_x), pos_label=\"PortScan\"))\n",
    "print(\"DT Test Specificity :: \", metrics.recall_score(test_y, dt.predict(test_x), pos_label=\"BENIGN\"))\n",
    "print(\"DT Test Precision :: \", metrics.precision_score(test_y, dt.predict(test_x), pos_label=\"PortScan\"))\n",
    "print(\"DT Test F1 Score :: \", metrics.f1_score(test_y, dt.predict(test_x), average=None, labels=trafficLabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = pd.DataFrame(columns=['Total Fwd Packets', 'Total Backward Packets',\n",
    " 'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
    " 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Mean',\n",
    " 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n",
    " 'Fwd URG Flags', 'Bwd URG Flags', 'Average Packet Size',\n",
    " 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Label'])\n",
    "\n",
    "output_row = 0\n",
    "\n",
    "for row_index, (prediction, label) in enumerate(zip (rfc.predict(test_x), test_y)):\n",
    "    if prediction != label:\n",
    "        row = test_x.iloc[row_index].values\n",
    "        row = np.append(row, test_y.iloc[row_index])\n",
    "        errors.loc[output_row] = row\n",
    "        output_row += 1\n",
    "        \n",
    "errors.to_csv('errors.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Avg Fwd Segment Size, Score: 0.20519\n",
      "Feature: Total Length of Fwd Packets, Score: 0.19516\n",
      "Feature: Average Packet Size, Score: 0.17197\n",
      "Feature: Total Fwd Packets, Score: 0.12493\n",
      "Feature: Total Length of Bwd Packets, Score: 0.11594\n",
      "Feature: PSH Flag Count, Score: 0.07763\n",
      "Feature: Fwd IAT Max, Score: 0.06383\n",
      "Feature: Avg Bwd Segment Size, Score: 0.01441\n",
      "Feature: Fwd IAT Mean, Score: 0.00894\n",
      "Feature: URG Flag Count, Score: 0.00759\n",
      "Feature: Fwd IAT Min, Score: 0.00685\n",
      "Feature: Bwd IAT Std, Score: 0.00274\n",
      "Feature: Bwd IAT Max, Score: 0.00157\n",
      "Feature: Total Backward Packets, Score: 0.00141\n",
      "Feature: Fwd IAT Std, Score: 0.00089\n",
      "Feature: Bwd IAT Min, Score: 0.00077\n",
      "Feature: Bwd IAT Mean, Score: 0.00016\n",
      "Feature: Fwd PSH Flags, Score: 0.00000\n",
      "Feature: Bwd PSH Flags, Score: 0.00000\n",
      "Feature: Fwd URG Flags, Score: 0.00000\n",
      "Feature: Bwd URG Flags, Score: 0.00000\n"
     ]
    }
   ],
   "source": [
    "importance = rfc.feature_importances_\n",
    "# Summarize feature importance, according to Random forest\n",
    "for i,v in sorted(enumerate(importance), key=lambda x:x[1], reverse=True):\n",
    "\tprint('Feature: %s, Score: %.5f' % (selected_features[i],v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(test_flow_data[selected_features[:-1]],\n",
    "                                                    test_flow_data[selected_features[-1]], \n",
    "                                                    train_size=0.67, \n",
    "                                                    test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train RFC: 0.015625s\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "start1 = time.process_time()\n",
    "rfc.fit(train_x, train_y)\n",
    "\n",
    "print('Time to train RFC: ' + str(time.process_time() - start1) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  0]\n",
      " [ 0 71]]\n",
      "Random forest Test Accuracy ::  1.0\n",
      "Random forest F1 Score ::  [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "trafficLabels = ['BENIGN', 'PortScan']\n",
    "\n",
    "# Print out the results\n",
    "print(metrics.confusion_matrix(test_y, rfc.predict(test_x), labels=trafficLabels))\n",
    "print(\"Random forest Test Accuracy :: \", metrics.accuracy_score(test_y, rfc.predict(test_x)))\n",
    "print(\"Random forest F1 Score :: \", metrics.f1_score(test_y, rfc.predict(test_x), average=None, labels=trafficLabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Total Length of Fwd Packets, Score: 0.42855\n",
      "Feature: Fwd IAT Std, Score: 0.19744\n",
      "Feature: Total Fwd Packets, Score: 0.10000\n",
      "Feature: Avg Fwd Segment Size, Score: 0.10000\n",
      "Feature: Average Packet Size, Score: 0.06914\n",
      "Feature: Total Length of Bwd Packets, Score: 0.05047\n",
      "Feature: Avg Bwd Segment Size, Score: 0.04195\n",
      "Feature: Bwd IAT Max, Score: 0.01245\n",
      "Feature: Total Backward Packets, Score: 0.00000\n",
      "Feature: Fwd IAT Mean, Score: 0.00000\n",
      "Feature: Fwd IAT Max, Score: 0.00000\n",
      "Feature: Fwd IAT Min, Score: 0.00000\n",
      "Feature: Bwd IAT Mean, Score: 0.00000\n",
      "Feature: Bwd IAT Std, Score: 0.00000\n",
      "Feature: Bwd IAT Min, Score: 0.00000\n",
      "Feature: Fwd PSH Flags, Score: 0.00000\n",
      "Feature: Bwd PSH Flags, Score: 0.00000\n",
      "Feature: Fwd URG Flags, Score: 0.00000\n",
      "Feature: Bwd URG Flags, Score: 0.00000\n"
     ]
    }
   ],
   "source": [
    "importance = rfc.feature_importances_\n",
    "# Summarize feature importance, according to Random forest\n",
    "for i,v in sorted(enumerate(importance), key=lambda x:x[1], reverse=True):\n",
    "\tprint('Feature: %s, Score: %.5f' % (selected_features[i],v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = flow_data[selected_features[:-1]]\n",
    "train_y = flow_data[selected_features[-1]]\n",
    "\n",
    "test_x = test_flow_data[selected_features[:-1]]\n",
    "test_y = test_flow_data[selected_features[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train RFC: 1.546875s\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "start1 = time.process_time()\n",
    "rfc.fit(train_x, train_y)\n",
    "\n",
    "print('Time to train RFC: ' + str(time.process_time() - start1) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Total Length of Fwd Packets, Score: 0.18770\n",
      "Feature: Avg Fwd Segment Size, Score: 0.16970\n",
      "Feature: Average Packet Size, Score: 0.15304\n",
      "Feature: Total Fwd Packets, Score: 0.13227\n",
      "Feature: Avg Bwd Segment Size, Score: 0.09311\n",
      "Feature: Fwd IAT Mean, Score: 0.06955\n",
      "Feature: Fwd IAT Max, Score: 0.06449\n",
      "Feature: Fwd IAT Min, Score: 0.06307\n",
      "Feature: Total Length of Bwd Packets, Score: 0.05415\n",
      "Feature: Fwd IAT Std, Score: 0.00714\n",
      "Feature: Total Backward Packets, Score: 0.00243\n",
      "Feature: Bwd IAT Mean, Score: 0.00158\n",
      "Feature: Bwd IAT Min, Score: 0.00083\n",
      "Feature: Bwd IAT Max, Score: 0.00050\n",
      "Feature: Bwd IAT Std, Score: 0.00042\n",
      "Feature: Fwd PSH Flags, Score: 0.00002\n",
      "Feature: Bwd PSH Flags, Score: 0.00000\n",
      "Feature: Fwd URG Flags, Score: 0.00000\n",
      "Feature: Bwd URG Flags, Score: 0.00000\n"
     ]
    }
   ],
   "source": [
    "importance = rfc.feature_importances_\n",
    "# Summarize feature importance, according to Random forest\n",
    "for i,v in sorted(enumerate(importance), key=lambda x:x[1], reverse=True):\n",
    "\tprint('Feature: %s, Score: %.5f' % (selected_features[i],v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   0]\n",
      " [200   0]]\n",
      "Random forest Test Accuracy ::  0.33774834437086093\n",
      "Random forest F1 Score ::  [0.5049505 0.       ]\n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marek\\PycharmProjects\\DP\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "trafficLabels = ['BENIGN', 'PortScan']\n",
    "\n",
    "# Print out the results\n",
    "print(metrics.confusion_matrix(test_y, rfc.predict(test_x), labels=trafficLabels))\n",
    "print(\"Random forest Test Accuracy :: \", metrics.accuracy_score(test_y, rfc.predict(test_x)))\n",
    "print(\"Random forest F1 Score :: \", metrics.f1_score(test_y, rfc.predict(test_x), average=None, labels=trafficLabels))\n",
    "print(test_x['Total Length of Fwd Packets'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train RFC: 12.34375s\n"
     ]
    }
   ],
   "source": [
    "standardsc = StandardScaler()\n",
    "mmsc = MinMaxScaler()\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "start1 = time.process_time()\n",
    "rfc.fit(standardsc.fit_transform(train_x), train_y)\n",
    "\n",
    "print('Time to train RFC: ' + str(time.process_time() - start1) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   0]\n",
      " [200   0]]\n",
      "Random forest Test Accuracy ::  0.33774834437086093\n",
      "Random forest F1 Score ::  [0.5049505 0.       ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marek\\PycharmProjects\\DP\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "trafficLabels = ['BENIGN', 'PortScan']\n",
    "\n",
    "# Print out the results\n",
    "print(metrics.confusion_matrix(test_y, rfc.predict(standardsc.fit_transform(test_x)), labels=trafficLabels))\n",
    "print(\"Random forest Test Accuracy :: \", metrics.accuracy_score(test_y, rfc.predict(standardsc.fit_transform(test_x))))\n",
    "print(\"Random forest F1 Score :: \", metrics.f1_score(test_y, rfc.predict(standardsc.fit_transform(test_x)), average=None, labels=trafficLabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Total Length of Fwd Packets, Score: 0.25640\n",
      "Feature: Average Packet Size, Score: 0.16411\n",
      "Feature: Avg Fwd Segment Size, Score: 0.14966\n",
      "Feature: Fwd IAT Max, Score: 0.10712\n",
      "Feature: Total Length of Bwd Packets, Score: 0.08540\n",
      "Feature: Avg Bwd Segment Size, Score: 0.08359\n",
      "Feature: Fwd IAT Min, Score: 0.06299\n",
      "Feature: Total Fwd Packets, Score: 0.05847\n",
      "Feature: Total Backward Packets, Score: 0.01763\n",
      "Feature: Fwd IAT Std, Score: 0.00520\n",
      "Feature: Fwd IAT Mean, Score: 0.00386\n",
      "Feature: Bwd IAT Min, Score: 0.00172\n",
      "Feature: Bwd IAT Max, Score: 0.00158\n",
      "Feature: Bwd IAT Std, Score: 0.00126\n",
      "Feature: Bwd IAT Mean, Score: 0.00096\n",
      "Feature: Fwd PSH Flags, Score: 0.00004\n",
      "Feature: Bwd PSH Flags, Score: 0.00000\n",
      "Feature: Fwd URG Flags, Score: 0.00000\n",
      "Feature: Bwd URG Flags, Score: 0.00000\n"
     ]
    }
   ],
   "source": [
    "importance = rfc.feature_importances_\n",
    "# Summarize feature importance, according to Random forest\n",
    "for i,v in sorted(enumerate(importance), key=lambda x:x[1], reverse=True):\n",
    "\tprint('Feature: %s, Score: %.5f' % (selected_features[i],v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
